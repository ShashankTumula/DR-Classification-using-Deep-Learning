{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShashankTumula/DR-Classification-using-Deep-Learning/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r16Ul6P9TNqD",
        "outputId": "51d42322-4d8b-43b5-9c39-d20499004ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### IMPORT LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os.path import exists\n",
        "from numba import cuda\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torchvision.transforms\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as functional\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "!pip install albumentations==0.4.6\n",
        "import albumentations\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpB5y23SyB72",
        "outputId": "820bdcc6-0114-4bb5-f193-5fae3228ddc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/117.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.13.1)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (6.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (4.10.0.84)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.23.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.34.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.0.6)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.3)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2024.8.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65152 sha256=77b798a5f3d440e03bf7761b947b56d065b92b7dbdb3aa84729be6bcd71f84af\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/d7/0c/6ed42fd872f7d1af78b25045f8b16be330f2c70ae72c83e37d\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.14\n",
            "    Uninstalling albumentations-1.4.14:\n",
            "      Successfully uninstalled albumentations-1.4.14\n",
            "Successfully installed albumentations-0.4.6\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=302050c53516edb3feeb106f69237fa8bd780cbea70d948a8bb428905c595187\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "RjpEtRyM5KSq",
        "outputId": "bfbe4307-2df8-4f48-800d-5530189b9591"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/diabetic-retinopathy/2015_resized/trainLabels.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-498caea035a6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Diagnosis LEVEL-WISE - Training Data Class Distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/diabetic-retinopathy/2015_resized/trainLabels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/diabetic-retinopathy/aptos_resized_150x150/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/diabetic-retinopathy/2015_resized/trainLabels.csv'"
          ]
        }
      ],
      "source": [
        "#### Diagnosis LEVEL-WISE - Training Data Class Distribution\n",
        "train  = pd.read_csv('/content/drive/MyDrive/diabetic-retinopathy/2015_resized/trainLabels.csv')\n",
        "validation = pd.read_csv('/content/drive/MyDrive/diabetic-retinopathy/aptos_resized_150x150/train.csv')\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "plt.hist(train['level'])\n",
        "plt.title('Training Data - Class Distribution')\n",
        "plt.ylabel('Number of DataPoints')\n",
        "plt.xlabel('Diagnosis Level')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Distribution of Training Data according to Level of Diabetic Retinopathy\n",
        "print(\"Total Number of Training DataPoints :\"+str(train.shape[0]))\n",
        "print('-' * 16)\n",
        "print(train['level'].value_counts())\n",
        "print('-' * 16)\n",
        "print(\"Total Number of Validation DataPoints :\"+str(validation.shape[0]))\n"
      ],
      "metadata": {
        "id": "S4rPFW8d7itN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_Function(Dataset):\n",
        "    def __init__(self, directory, csv_file_loc, train=True, transform=None):\n",
        "        super().__init__()\n",
        "        self.data = pd.read_csv(csv_file_loc)\n",
        "        self.directory = directory\n",
        "        self.image_files = os.listdir(directory)\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0] if self.train else len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            image_file, label = self.data.iloc[index]\n",
        "        else:\n",
        "            image_file, label = self.image_files[index], -1\n",
        "            image_file = image_file.replace(\".png\", \"\")\n",
        "            image_file = image_file.replace(\".jpeg\", \"\")\n",
        "        if exists(os.path.join(self.directory, image_file+\".png\")):\n",
        "          image = np.array(Image.open(os.path.join(self.directory, image_file+\".png\")))\n",
        "        elif exists(os.path.join(self.directory, image_file+\".jpeg\")):\n",
        "          image = np.array(Image.open(os.path.join(self.directory, image_file+\".jpeg\")))\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label, image_file\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SEMNEOT7Jyc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra9VZ0su0f-6"
      },
      "outputs": [],
      "source": [
        "#CONFIGURATIONS FOR MODEL\n",
        "\n",
        "\n",
        "NUM_WORKERS = 1\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 1\n",
        "WEIGHT_DECAY = 5e-4\n",
        "LEARNING_RATE = 3e-5\n",
        "\n",
        "CHECKPOINT_FILE = \"/content/drive/MyDrive/b.pth.tar\"\n",
        "\n",
        "image_size = 150\n",
        "\n",
        "PIN_MEMORY = True\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# augs = albumentations.Compose([albumentations.Resize(height = image_size,\n",
        "#                            width  = image_size),\n",
        "#                   albumentations.Normalize(mean = (0, 0, 0),\n",
        "#                               std  = (1, 1, 1)),\n",
        "#                   ToTensorV2()])\n",
        "\n",
        "\n",
        "# image_dataset= Dataset_Function(csv_file_loc = \"/content/drive/MyDrive/2015_resized/trainLabels.csv\",\n",
        "#                          directory = \"/content/drive/MyDrive/2015_resized/train_resized_150\",\n",
        "#                          transform = augs)\n",
        "# image_loader = DataLoader(image_dataset,\n",
        "#                           batch_size  = BATCH_SIZE,\n",
        "#                           shuffle     = False,\n",
        "#                           num_workers = NUM_WORKERS,\n",
        "#                           pin_memory  = PIN_MEMORY)\n",
        "\n",
        "\n",
        "# psum    = torch.tensor([0.0, 0.0, 0.0])\n",
        "# psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "# for input in tqdm(image_loader):\n",
        "#   psum += torch.sum(input,dim =[0, 2, 3])\n",
        "#   psum_sq += torch.sum((input ** 2), dim = [0, 2, 3])\n",
        "\n",
        "# count = len(train) * image_size * image_size\n",
        "\n",
        "# total_mean = psum / count\n",
        "# total_var  = (psum_sq / count) - (total_mean ** 2)\n",
        "# total_std  = torch.sqrt(total_var)\n",
        "\n",
        "# Data augmentation for images\n",
        "\n",
        "#we get mean as [0.3753, 0.2609, 0.1866] and std as [0.2900, 0.2098, 0.1701] by running the above code on training dataset, to normalize.\n",
        "\n",
        "train_transforms = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.Resize(width=image_size, height=image_size),\n",
        "        albumentations.RandomCrop(height=image_size, width=image_size),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "validation_transforms = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.Resize(height=image_size, width=image_size),\n",
        "        albumentations.Normalize(\n",
        "            mean=[0.3753, 0.2609, 0.1866],\n",
        "            std=[0.2900, 0.2098, 0.1701],\n",
        "            max_pixel_value=255.0,\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(path, sigmaX = 10, do_random_crop = False):\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return image\n",
        "\n",
        "def prepare_image_transformed(path, sigmaX = 10, do_random_crop = False):\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (int(image_size), int(image_size)))\n",
        "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), sigmaX), -4, 128)\n",
        "\n",
        "    return image\n",
        "\n",
        "sample_transforms = albumentations.Compose([albumentations.Resize(height = image_size,\n",
        "                           width  = image_size),\n",
        "                  ToTensorV2()])\n",
        "\n",
        "class DatasetSample(Dataset):\n",
        "\n",
        "    def __init__(self, data, directory, transform = None):\n",
        "        self.data      = data\n",
        "        self.directory = directory\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.directory, self.data.loc[idx, 'image'] + '.jpeg')\n",
        "        img_name    = prepare_image(img_name)\n",
        "        transformed_image = self.transform(image=img_name)[\"image\"]\n",
        "        label    = torch.tensor(self.data.loc[idx, 'level'])\n",
        "        return {'image': transformed_image, 'label': label}\n",
        "\n",
        "class DatasetSample_transformed(Dataset):\n",
        "\n",
        "    def __init__(self, data, directory, transform = None):\n",
        "        self.data      = data\n",
        "        self.directory = directory\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.directory, self.data.loc[idx, 'image'] + '.jpeg')\n",
        "        img_name    = prepare_image_transformed(img_name)\n",
        "        transformed_image = self.transform(image=img_name)[\"image\"]\n",
        "        label    = torch.tensor(self.data.loc[idx, 'level'])\n",
        "        return {'image': transformed_image, 'label': label}\n",
        "\n",
        "\n",
        "sample_original_dataset = DatasetSample(data = pd.read_csv('/content/drive/MyDrive/Diabetic_Retinopathy/diabetic-retinopathy-detection/trainLabels.csv'),\n",
        "                         directory = \"/content/drive/MyDrive/Diabetic_Retinopathy/diabetic-retinopathy-detection/train\",\n",
        "                         transform = sample_transforms)\n",
        "\n",
        "\n",
        "sample_transformed_dataset = DatasetSample_transformed(data = pd.read_csv('/content/drive/MyDrive/2015_resized/trainLabels.csv'),\n",
        "                         directory = \"/content/drive/MyDrive/2015_resized/train_resized_150\",\n",
        "                         transform = train_transforms)\n",
        "\n",
        "sample_original_loader = DataLoader(sample_original_dataset,\n",
        "                          batch_size  = 10,\n",
        "                          shuffle     = False,\n",
        "                          num_workers = NUM_WORKERS,\n",
        "                          pin_memory  = PIN_MEMORY)\n",
        "\n",
        "sample_transformed_loader = DataLoader(sample_transformed_dataset,\n",
        "                          batch_size  = 10,\n",
        "                          shuffle     = False,\n",
        "                          num_workers = NUM_WORKERS,\n",
        "                          pin_memory  = PIN_MEMORY)\n",
        "\n"
      ],
      "metadata": {
        "id": "nXUYOmRIocJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch, data in enumerate(sample_original_loader):\n",
        "\n",
        "    inputs = data['image']\n",
        "    labels = data['label'].view(-1, 1)\n",
        "\n",
        "    fig = plt.figure(figsize = (16, 9))\n",
        "    for i in range(len(labels)):\n",
        "        ax = fig.add_subplot(2, len(labels)/2, i + 1, xticks = [], yticks = [])\n",
        "        plt.imshow(inputs[i].numpy().transpose(1, 2, 0))\n",
        "        ax.set_title(labels.numpy()[i])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "7Ouh43dyqW2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch, data in enumerate(sample_transformed_loader):\n",
        "\n",
        "    inputs = data['image']\n",
        "    labels = data['label'].view(-1, 1)\n",
        "\n",
        "    fig = plt.figure(figsize = (16, 9))\n",
        "    for i in range(len(labels)):\n",
        "        ax = fig.add_subplot(2, len(labels)/2, i + 1, xticks = [], yticks = [])\n",
        "        inputs[i] = torchvision.transforms.Grayscale()(inputs[i])\n",
        "        plt.imshow(inputs[i].numpy().transpose(1, 2, 0))\n",
        "        ax.set_title(labels.numpy()[i])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "dDHf8rWjocQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5-DToFW58l_"
      },
      "outputs": [],
      "source": [
        "def accuracy_function(loader, model, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    list_preds, list_labels = [], []\n",
        "    list_preds_new, list_labels_new = [], []\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    num_correct_classes = 0\n",
        "    num_samples_classes = 0\n",
        "\n",
        "    for x, y, filename in tqdm(loader):\n",
        "        x = x.to(device=device)\n",
        "        y = y.to(device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x)\n",
        "\n",
        "        predictions_new = predictions.detach().clone()\n",
        "        predictions_new = predictions_new.long().view(-1)\n",
        "\n",
        "        predictions[predictions < 0.5] = 0\n",
        "        predictions[predictions >= 0.5] = 1\n",
        "\n",
        "        predictions_new[predictions_new < 0.5] = 0\n",
        "        predictions_new[(predictions_new >= 0.5) & (predictions_new < 1.5)] = 1\n",
        "        predictions_new[(predictions_new >= 1.5) & (predictions_new < 2)] = 2\n",
        "        predictions_new[(predictions_new >= 2) & (predictions_new < 3)] = 3\n",
        "        predictions_new[(predictions_new >= 3)] = 4\n",
        "\n",
        "        predictions = predictions.long().view(-1)\n",
        "        y_new = y.detach().clone()\n",
        "        y_new = y_new.view(-1)\n",
        "\n",
        "        y = y.view(-1)\n",
        "\n",
        "        y[y < 1] = 0\n",
        "        y[y >= 1] = 1\n",
        "\n",
        "        num_correct_classes += (predictions_new == y_new ).sum()\n",
        "        num_samples_classes += predictions_new.shape[0]\n",
        "\n",
        "        num_correct += (predictions == y ).sum()\n",
        "        num_samples += predictions.shape[0]\n",
        "\n",
        "        list_labels.append(y.detach().cpu().numpy())\n",
        "        list_preds.append(predictions.detach().cpu().numpy())\n",
        "\n",
        "        list_labels_new.append(y_new.detach().cpu().numpy())\n",
        "        list_preds_new.append(predictions_new.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "    print(\"For Diabetic Retinopathy Detection Accuracy:\")\n",
        "    print()\n",
        "    print(f\" {num_correct} / {num_samples} images were predicted correctly, with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
        "    print()\n",
        "    confusion_matrix_detection = confusion_matrix(np.concatenate(list_labels, axis=0, dtype=np.int64), np.concatenate(\n",
        "        list_preds, axis=0, dtype=np.int64))\n",
        "    cmd = ConfusionMatrixDisplay(confusion_matrix_detection, display_labels=['Yes','No'])\n",
        "    cmd.plot()\n",
        "    plt.show()\n",
        "    plt.savefig(f'{num_correct}.png')\n",
        "    print(\"For Classwise Accuracy:\")\n",
        "    print()\n",
        "    print(f\"{num_correct_classes} / {num_samples_classes}  images were predicted correctly, with accuracy {float(num_correct_classes) / float(num_samples_classes) * 100:.2f}\")\n",
        "    print()\n",
        "    confusion_matrix_classes = confusion_matrix(np.concatenate(list_labels_new, axis=0, dtype=np.int64), np.concatenate(\n",
        "        list_preds_new, axis=0, dtype=np.int64))\n",
        "    cmd = ConfusionMatrixDisplay(confusion_matrix_classes, display_labels=['0','1','2','3','4'])\n",
        "    cmd.plot()\n",
        "    plt.show()\n",
        "    plt.savefig(f'{num_correct_classes}.png')\n",
        "    model.train()\n",
        "    return np.concatenate(list_preds, axis=0, dtype=np.int64), np.concatenate(\n",
        "        list_labels, axis=0, dtype=np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def epoch_wise_train_function(loader, model, optimizer, loss_fn, scaler, device):\n",
        "    losses = []\n",
        "    loop = tqdm(loader)\n",
        "    for batch_idx, (data, targets, _) in enumerate(loop):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "            scores = model(data)\n",
        "            loss = loss_fn(scores, targets.unsqueeze(1).float())\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"The Loss average over epoch is: {sum(losses)/len(losses)}\")"
      ],
      "metadata": {
        "id": "N_UW2LEuypop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rjbL8cU6A-l"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    training_dataset = Dataset_Function(\n",
        "        directory=\"/content/drive/MyDrive/2015_resized/train_resized_150\",\n",
        "        csv_file_loc=\"/content/drive/MyDrive/2015_resized/trainLabels.csv\",\n",
        "        transform=validation_transforms,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        training_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    validation_dataset = Dataset_Function(\n",
        "      directory=\"/content/drive/MyDrive/aptos_resized_150x150/train_images_resized_150\",\n",
        "      csv_file_loc=\"/content/drive/MyDrive/aptos_resized_150x150/train.csv\",\n",
        "      transform=validation_transforms,\n",
        "    )\n",
        "\n",
        "    validation_loader = DataLoader(\n",
        "        validation_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=1,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    model = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
        "    model._fc = nn.Linear(1408, 1)\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_wise_train_function(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "        preds, labels = accuracy_function(validation_loader, model, DEVICE)\n",
        "\n",
        "    print(\"Results for efficientnet-b2\")\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
        "    model._fc = nn.Linear(1536, 1)\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_wise_train_function(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "        predictions, labels = accuracy_function(validation_loader, model, DEVICE)\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    model = EfficientNet.from_pretrained(\"efficientnet-b4\")\n",
        "    model._fc = nn.Linear(1792, 1)\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_wise_train_function(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "        predictions, labels = accuracy_function(validation_loader, model, DEVICE)\n",
        "\n",
        "    print(\"Results for efficientnet-b4\")\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_26n0ASF6ag0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}